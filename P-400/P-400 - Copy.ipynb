{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagarism Detection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------Supervised By:--------------------------------------------------\n",
    "### -----------------------------------------------------------Ranit Devnath Akash -----------------------------------------------------------\n",
    "### ----------------------------------------------------------Lecturer, Dept. of CSE, ----------------------------------------------------------\n",
    "### ----------------------------------------------------Metropolitan University,Sylhet.------------------------------------------------------\n",
    "## ------------------------------------------------Word ta Buligesi:--------------------------------------------------\n",
    "### --------------------Bisahl Shyam Pukayastha-----------------------------Name:Burhan Uddin----------------------------------\n",
    "### --------------------ID: 152-115-000--------------------------------------------ID:153-115-019-------------------------------------------\n",
    "### --------------------CSE 36th Batch,MU--------------------------------------CSE 37th Batch,MU-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import codecs\n",
    "import os\n",
    "import json\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "from bengali_stemmer.rafikamal2014 import RafiStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'অন্ধকার'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem_word('অন্ধকারে')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Important Link] C:\\Users\\Burhan\\AppData\\Roaming\\nltk_data\\corpora\\stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #For English Language\n",
    "stopword = set(stopwords.words('english'))\n",
    "punctuation = set(stopwords.words('punctuation.txt'))\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['এই ', 'ও ', 'থেকে', 'করে', 'এ', 'না', 'ওই', 'এক্', 'নিয়ে', 'করা', 'বলেন ', 'সঙ্গে ', 'যে', 'এব', 'তা', 'আর ', 'কোনো', 'বলে', 'সেই', 'দিন', 'হয় ', 'কি', 'দু', 'পরে', 'সব', 'দেওয়া', 'মধ্যে', 'এর', 'সি', 'শুরু ', 'কাজ', 'কিছু ', 'কাছে', 'সে', 'তবে', 'বা', 'বন', 'আগে', 'জ্নজন', 'পি', 'পর', 'তো', 'ছিল', 'এখন', 'আমরা', 'প্রায়', 'দুই ', 'আমাদের', 'তাই', 'অন্য', 'গিয়ে', 'প্রযন্ত', 'মনে', 'নতুন', 'মতো', 'কেখা', 'প্রথম ', 'আজ', 'টি ', 'ধামার', 'অনেক', 'বিভিন্ন ', 'র ', 'হাজার', 'জানা', 'নয়', 'অবশ্য', 'বেশি', 'এস', 'করে', 'কে', 'হতে', 'বি', 'কয়েক', 'সহ  ', 'বেশ', 'এমন', 'এমনি', 'কেন', 'কেউ', 'নেওয়া', 'চেষ্টা', 'লক্ষ  ', 'বলা', 'কারণ ', 'আছে', 'শুধু ', 'তখন', 'যা', 'এসে', 'চার', 'ছিল', 'যদি', 'আবার', 'কোটি ', 'উত্তর', 'সামনে', 'উপর', 'বক্তব্য ', 'এত', 'প্রাথমিক', 'উপরে', 'আছে', 'প্রতি', 'কাজে', 'যখন', 'খুব', 'বহু', 'গেল', 'পেয়্র্', 'চালু', 'ই ', 'নাগাদ', 'থাকা', 'পাচ', 'যাওয়া', 'রকম', 'সাধারণ', 'কমনে']\n",
      "['.', ',', '?', ';', \"'\", '\"', ':', '(', ')', '!', '@', '#', '—', '$', '%', '^', '&', '*', '_', '+', '=', '{', '}', '[', ']', '\\\\', '|', '/', '<', '>', '~', '`', '।', '।', '—']\n"
     ]
    }
   ],
   "source": [
    "#stopword = set(stopwords.words('bangla.txt'))\n",
    "#print(stopword)\n",
    "x = codecs.open('C:/Users/Burhan/Desktop/P-400/bangla.txt',encoding='utf-8')\n",
    "stopword1 = x.read()\n",
    "stopword1 = stopword1.replace('\\ufeff','')\n",
    "stopword1 = stopword1.split('\\r\\n')\n",
    "print(stopword1)\n",
    "#punctuation = set(stopwords.words('punctuation.txt'))\n",
    "\n",
    "x = codecs.open('C:/Users/Burhan/Desktop/P-400/punctuation.txt',encoding='utf-8')\n",
    "punctuation = x.read()\n",
    "punctuation = punctuation.replace('\\ufeff','')\n",
    "punctuation = punctuation.split('\\r\\n')\n",
    "print(punctuation)\n",
    "\n",
    "stemmer = RafiStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL THE CUSTOM FUCTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOP_WORD_REMOVAL(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STOP_WORD_REMOVAL(token):\n",
    "    filtered_tokens = []\n",
    "    for w in token:\n",
    "        if w not in stopword1:\n",
    "            if w not in punctuation:\n",
    "                filtered_tokens.append(w)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms_Removal(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Synonyms_Removal(token):\n",
    "  #  print(token)\n",
    "  #  print('----------------------------------------------------------')\n",
    "    synonyms_removed_words = []\n",
    "    for t in token:\n",
    "        found = False\n",
    "        for sd in synonyms_dataset:\n",
    "            if t in sd:\n",
    "                synonyms_removed_words.append(sd[0])\n",
    "                found = True\n",
    "                continue\n",
    "        if not found:\n",
    "            synonyms_removed_words.append(t)\n",
    "                \n",
    "   # print(synonyms_removed_words)\n",
    "   # print('__________________________________________________________')\n",
    "    return synonyms_removed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check_Synonyms_Word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Synonyms_Word(word):\n",
    "    for sd in synonyms_dataset:\n",
    "        if word in sd:\n",
    "            print('FOUND!!!')\n",
    "            print(word+'==='+sd[0])\n",
    "            return\n",
    "    print('NOT FOUND!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N_GRAM_CONVERSION(stage3,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_GRAM_CONVERSION(stage3,n):\n",
    "    #n = 2 #n-grams size\n",
    "    n_grams = []\n",
    "    index = 0\n",
    "    while index <= len(stage3)-n:\n",
    "        s = \"\"\n",
    "        for x in range(n):\n",
    "            s += stage3[index+x]\n",
    "            if x<n-1:\n",
    "                s += ' '\n",
    "        n_grams.append(s)\n",
    "        index = index + 1\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE_TRIE(index,N_gram,dictionary,documentID,count_N_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CREATE_TRIE(index,N_gram,dictionary,documentID,count_N_gram):\n",
    "   # print(index,N_gram,dictionary,documentID,count_N_gram)\n",
    "    if index < len(N_gram)-1:\n",
    "        if N_gram[index] not in dictionary:\n",
    "            print(N_gram[index]+' not in dictionary')\n",
    "            dictionary[N_gram[index]] = {}\n",
    "        CREATE_TRIE(index+1,N_gram,dictionary[N_gram[index]],documentID,count_N_gram)\n",
    "    else:\n",
    "        if N_gram[index] not in dictionary:\n",
    "            dictionary[N_gram[index]] = {'TOTAL':count_N_gram, documentID:count_N_gram}\n",
    "        else:\n",
    "            dictionary[N_gram[index]]['TOTAL'] += count_N_gram\n",
    "            if documentID not in dictionary:\n",
    "                dictionary[N_gram[index]][documentID] = 0\n",
    "            dictionary[N_gram[index]][documentID] += count_N_gram\n",
    "     #   print(dictionary)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Files In DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: 'C:/Users/Burhan/Desktop/P-400/Dataset/Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-93a0d99b4d48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# for saving memory we can delete our dataset once we load it\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: 'C:/Users/Burhan/Desktop/P-400/Dataset/Y'"
     ]
    }
   ],
   "source": [
    "# Version 3.0\n",
    "PATH = 'C:/Users/Burhan/Desktop/P-400/Dataset'\n",
    "Files = os.listdir(PATH)\n",
    "corpus = {}\n",
    "for f in Files:\n",
    "    if f.endswith(\".txt\"):\n",
    "        x = codecs.open(PATH+'/'+f, encoding='utf-8')\n",
    "        #corpus.append(x.read()) for list we change it now on dict to track the file name\n",
    "        corpus[f] = x.read()\n",
    "        x.close()\n",
    "    os.remove(PATH+'/'+f)  # for saving memory we can delete our dataset once we load it\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "for c in corpus:\n",
    "    c = c.replace('\\ufeff','')\n",
    "    c = c.replace('।', '.')\n",
    "    #tokens.append(word_tokenize(c))\n",
    "    tokens[c] = word_tokenize(corpus[c])\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens_list = {}\n",
    "for t in tokens:\n",
    "    swr = STOP_WORD_REMOVAL(tokens[t])\n",
    "    if len(swr)>0:                    # Removing Empty List\n",
    "        #filtered_tokens_list.append(swr)\n",
    "        filtered_tokens_list[t] = swr\n",
    "#filtered_tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "steamed_token_list = {}\n",
    "stage2 = []\n",
    "for flt in filtered_tokens_list:\n",
    "    stage2 = []\n",
    "    for s in filtered_tokens_list[flt]:\n",
    "        #stage2.append(stemmer.stem(s))         for English\n",
    "        temp = stemmer.stem_word(s)\n",
    "        stage2.append(stemmer.stem_word(temp))\n",
    "    #steamed_token_list.append(stage2)\n",
    "    steamed_token_list[flt] = stage2\n",
    "#steamed_token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Converting into n-grams lets check synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synonyms\n",
    "#synonyms\n",
    "x = codecs.open('C:/Users/Burhan/Desktop/P-400/synonyms.txt', encoding='utf-8')\n",
    "synonyms = x.read()\n",
    "x.close()\n",
    "synonyms = synonyms.split('\\r\\n')\n",
    "synonyms[0] = synonyms[0].replace('\\ufeff','')\n",
    "\n",
    "synonyms_dataset = []\n",
    "for s in synonyms:\n",
    "    synonyms_dataset.append(s.split(','))\n",
    "#synonyms_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_removed_steamed_token_list = {}\n",
    "for stl in steamed_token_list:\n",
    "    #synonyms_removed_steamed_token_list.append(Synonyms_Removal(steamed_token_list[stl]))\n",
    "    synonyms_removed_steamed_token_list[stl] = Synonyms_Removal(steamed_token_list[stl])\n",
    "#print(len(steamed_token_list))\n",
    "#print(len(synonyms_removed_steamed_token_list))\n",
    "#synonyms_removed_steamed_token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Conversion into n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_grams_list = {}\n",
    "n = 2\n",
    "totalWord = n-1\n",
    "for stl in synonyms_removed_steamed_token_list:\n",
    "    #N_grams_list.append(N_GRAM_CONVERSION(stl,2))\n",
    "    N_grams_list [stl] = N_GRAM_CONVERSION(synonyms_removed_steamed_token_list[stl],n)\n",
    "    totalWord += len(N_grams_list [stl])\n",
    "#N_grams_list\n",
    "#totalWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams List:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSets = {}\n",
    "for Ngl in N_grams_list:\n",
    "    wordSets[Ngl] = dict.fromkeys( N_grams_list[Ngl], 0)\n",
    "#wordSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wS in wordSets:\n",
    "    for ngl in N_grams_list[wS]:\n",
    "        wordSets[wS][ngl] +=1\n",
    "#wordSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ/WRITE OUR TRIE DATASET(JSON):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DICT = {}    # its gonna load from a json file later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ FROM TRIE(JSON):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\ufeff': {'স': {'দ': {'র': {' ': {'দ': {'ক': {'্': {'ষ': {'ি': {'ণ': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}}},\n",
       " 'দ': {'ক': {'্': {'ষ': {'ি': {'ণ': {' ': {'ন': {'া': {'গ': {'র': {'ি': {'ক': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}},\n",
       "        'স': {'ু': {'র': {'ম': {'া': {'TOTAL': 2, '1.11.19.txt': 2}}}}},\n",
       "        'ম': {'ন': {'ো': {'র': {'ম': {'ভ': {'া': {'ব': {'TOTAL': 1,\n",
       "                '1.11.19.txt': 1}}}}}}}},\n",
       "        'চ': {'ন': {'্': {'ড': {'ি': {'প': {'ু': {'ল': {'স': {'্': {'থ': {'TOTAL': 1,\n",
       "                   '1.11.19.txt': 1}}}}}}}}}}}}}}}}},\n",
       "  'ৃ': {'শ': {'্': {'য': {'ম': {'া': {'ন': {' ': {'হ': {'ব': {'ে': {'।': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}}}}}}}},\n",
       "  '¶': {'ি': {'ণ': {' ': {'এ': {'ল': {'া': {'ক': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}},\n",
       "      'ন': {'া': {'গ': {'র': {'ি': {'ক': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  ' ': {'স': {'ং': {'গ': {'ঠ': {'ন': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       " 'ন': {'া': {'গ': {'র': {'ি': {'ক': {' ': {'ক': {'ম': {'ি': {'TOTAL': 2,\n",
       "           '1.11.19.txt': 2}}}}}}}}},\n",
       "  'ব': {'গ': {'ঠ': {'ি': {'ত': {' ': {'আ': {'দ': {'ি': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}}}},\n",
       "  'জ': {'র': {'ু': {'ল': {' ': {'ই': {'স': {'ল': {'া': {'ম': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}}},\n",
       " 'ক': {'ম': {'ি': {' ': {'অ': {'ভ': {'ি': {'ষ': {'ে': {'ক': {'TOTAL': 5,\n",
       "           '1.11.19.txt': 5}}}}}},\n",
       "     'স': {'ি': {'ল': {'ে': {'ট': {'TOTAL': 1, '1.11.19.txt': 1}}}},\n",
       "      'ভ': {'া': {'প': {'ত': {'ি': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       "    'উ': {'ন': {'ি': {' ': {'স': {'ে': {'ন': {'্': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  'র': {'প': {'ো': {'র': {'ে': {'শ': {'ন': {' ': {'দ': {'ক': {'্': {'ষ': {'ি': {'ণ': {'TOTAL': 1,\n",
       "                '1.11.19.txt': 1}}}}}},\n",
       "          'ম': {'ে': {'য়': {'র': {'TOTAL': 1, '1.11.19.txt': 1}}}},\n",
       "          'প': {'ক': {'্': {'ষ': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}}}}}},\n",
       "   'ছ': {'ি': {'।': {' ': {'ম': {'ে': {'য়': {'র': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}}}},\n",
       "  'থ': {' ': {'স': {'ত': {'্': {'য': {'ত': {'া': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}},\n",
       "   'া': {' ': {'ব': {'ল': {'ে': {'ন': {'।': {'TOTAL': 2,\n",
       "          '1.11.19.txt': 2}}}}}}}},\n",
       "  'া': {'উ': {'ন': {'্': {'স': {'ি': {'ল': {'র': {' ': {'ম': {'ো': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  '্': {'র': {'ী': {'ড়': {'া': {' ': {'স': {'ং': {'গ': {'ঠ': {'ক': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  'ব': {'ি': {'র': {' ': {'চ': {'ৌ': {'ধ': {'ু': {'র': {'ী': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}}},\n",
       " 'অ': {'ভ': {'ি': {'ষ': {'ে': {'ক': {' ': {'অ': {'ন': {'ু': {'ষ': {'্': {'ঠ': {'া': {'ন': {'TOTAL': 5,\n",
       "                '1.11.19.txt': 5}}}}}}}},\n",
       "        'ও': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       "  'ন': {'ু': {'ষ': {'্': {'ঠ': {'া': {'ন': {' ': {'ম': {'ে': {'য়': {'র': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}},\n",
       "          'প': {'্': {'র': {'ধ': {'া': {'ন': {'TOTAL': 3,\n",
       "                '1.11.19.txt': 3}}}}}}}}}}}}}},\n",
       "  'র': {'া': {'জ': {'ন': {'ৈ': {'ত': {'ি': {'ক': {' ': {'স': {'ং': {'গ': {'ঠ': {'ন': {'TOTAL': 1,\n",
       "                '1.11.19.txt': 1}}}}}}}}}}}}}},\n",
       "  'ত': {'ি': {'থ': {'ি': {'র': {' ': {'ব': {'ক': {'্': {'ত': {'ব': {'্': {'য': {'TOTAL': 7,\n",
       "               '1.11.19.txt': 7}}}}}}}}},\n",
       "      ' ': {'ছ': {'ি': {'TOTAL': 2, '1.11.19.txt': 2}}}}}}},\n",
       "  '্': {'য': {'া': {'ড': {'ভ': {'ো': {'ক': {'ে': {'ট': {' ': {'র': {'ফ': {'ি': {'ক': {'ু': {'ল': {'TOTAL': 1,\n",
       "                  '1.11.19.txt': 1}}}}}}}}}}}}}}}}},\n",
       " 'ম': {'ে': {'য়': {'র': {' ': {'স': {'ি': {'TOTAL': 1, '1.11.19.txt': 1}},\n",
       "      'আ': {'র': {'ি': {'ফ': {'ু': {'ল': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "      'গ': {'ত': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "  'ন': {'ো': {'র': {'ম': {'ভ': {'া': {'ব': {' ': {'স': {'া': {'জ': {'া': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1,\n",
       "              'ন': {'ো': {'র': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}}}}}}}}}},\n",
       "  'ো': {'ল': {'্': {'ল': {'া': {'র': {'গ': {'া': {'ঁ': {' ': {'ই': {'উ': {'ন': {'ি': {'য়': {'ন': {'TOTAL': 1,\n",
       "                  '1.11.19.txt': 1}}}}}}}}}}}}}}},\n",
       "   ' ': {'ম': {'ক': {'ন': {'TOTAL': 1, '1.11.19.txt': 1}}},\n",
       "    'আ': {'জ': {'ম': {'TOTAL': 2, '1.11.19.txt': 2}},\n",
       "     'ব': {'্': {'দ': {'ু': {'ল': {'TOTAL': 4, '1.11.19.txt': 4}}}}}}},\n",
       "   'হ': {'া': {'ম': {'্': {'ম': {'দ': {' ': {'আ': {'ব': {'ু': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  'ক': {'ন': {' ': {'ম': {'ি': {'TOTAL': 1, '1.11.19.txt': 1}}}}},\n",
       "  'ি': {' ': {'স': {'ভ': {'া': {'প': {'ত': {'ি': {'ত': {'্': {'ব': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  'ু': {'ক': {'্': {'ত': {'ি': {'য': {'ো': {'দ': {'্': {'ধ': {'া': {' ': {'অ': {'্': {'য': {'া': {'ড': {'ভ': {'ো': {'ক': {'ে': {'ট': {'TOTAL': 1,\n",
       "                        '1.11.19.txt': 1}}}}}}}}}}}}}}}}}}}}}}},\n",
       " 'স': {'ি': {' ': {'ক': {'র': {'প': {'ো': {'র': {'ে': {'শ': {'ন': {'TOTAL': 3,\n",
       "            '1.11.19.txt': 3}}}}}}},\n",
       "     'া': {'উ': {'ন': {'্': {'স': {'ি': {'ল': {'র': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}},\n",
       "   'ল': {'ে': {'ট': {' ': {'স': {'ি': {'TOTAL': 2, '1.11.19.txt': 2},\n",
       "        'দ': {'র': {'TOTAL': 1, '1.11.19.txt': 1}}},\n",
       "       'ন': {'ব': {'গ': {'ঠ': {'ি': {'ত': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "       'চ': {'ে': {'ম': {'্': {'ব': {'TOTAL': 3, '1.11.19.txt': 3}}}}}}}}}},\n",
       "  'ু': {'র': {'ম': {'া': {' ': {'ম': {'ন': {'ো': {'র': {'ম': {'ভ': {'া': {'ব': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}},\n",
       "       'ত': {'থ': {'া': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       "   'প': {'র': {'া': {'ম': {'র': {'্': {'শ': {' ': {'এ': {'ব': {'ং': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}}}}}}}},\n",
       "  'া': {'জ': {'া': {' ': {'প': {'র': {'ি': {'ক': {'ল': {'্': {'প': {'ন': {'া': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}}}},\n",
       "     'ন': {'ো': {'র': {' ': {'প': {'র': {'ি': {'ক': {'ল': {'্': {'প': {'ন': {'া': {'TOTAL': 1,\n",
       "                  '1.11.19.txt': 1}}}}}}}}}}}}}}},\n",
       "   'র': {'্': {'ব': {'ি': {'ক': {' ': {'স': {'হ': {'য': {'ো': {'গ': {'ি': {'ত': {'া': {'।': {'TOTAL': 1,\n",
       "                  '1.11.19.txt': 1}}}}}}}}}}}}}}}},\n",
       "  'দ': {'র': {' ': {'দ': {'ক': {'্': {'ষ': {'ি': {'ণ': {'TOTAL': 2,\n",
       "           '1.11.19.txt': 2}}}}},\n",
       "      '¶': {'ি': {'ণ': {'TOTAL': 2, '1.11.19.txt': 2}}}}}},\n",
       "   'স': {'্': {'য': {' ': {'শ': {'ি': {'ক': {'্': {'ষ': {'া': {'ব': {'ি': {'দ': {'TOTAL': 1,\n",
       "                '1.11.19.txt': 1}}}}}}}}}}}}}},\n",
       "  'ত': {'্': {'য': {'ত': {'া': {' ': {'প': {'া': {'ব': {'ে': {'ন': {'।': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}}}}}}}},\n",
       "  'হ': {'য': {'ো': {'গ': {'ি': {'ত': {'া': {'।': {' ': {'আ': {'ম': {'ি': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}},\n",
       "         ' ': {'প': {'্': {'র': {'ত': {'্': {'য': {'া': {'শ': {'া': {'TOTAL': 1,\n",
       "                   '1.11.19.txt': 1}}}}}}}}}}}}}}}},\n",
       "   'স': {'া': {'ধ': {'া': {'র': {'ণ': {' ': {'স': {'ম': {'্': {'প': {'া': {'দ': {'ক': {'TOTAL': 1,\n",
       "                 '1.11.19.txt': 1}}}}}}}}}}}}}}},\n",
       "  'ে': {'ন': {'্': {' ': {'স': {'ি': {'ল': {'ে': {'ট': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}}}},\n",
       "  'ং': {'গ': {'ঠ': {'ন': {' ': {'স': {'দ': {'র': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}},\n",
       "        'ভ': {'া': {'প': {'ত': {'ি': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "       'উ': {'প': {'দ': {'ে': {'ষ': {'্': {'TOTAL': 3,\n",
       "             '1.11.19.txt': 3,\n",
       "             'ট': {'া': {'ম': {'ন': {'্': {'ড': {'ল': {'ী': {'র': {'TOTAL': 1,\n",
       "                      '1.11.19.txt': 1}}}}}}}}}}}}}}}}},\n",
       "     'ক': {' ': {'ও': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "  'ভ': {'া': {' ': {'ত': {'ি': {'ন': {'ি': {'TOTAL': 1, '1.11.19.txt': 1}}}}},\n",
       "    'প': {'ত': {'ি': {' ': {'ম': {'ো': {'ল': {'্': {'ল': {'া': {'র': {'গ': {'া': {'ঁ': {'TOTAL': 1,\n",
       "                  '1.11.19.txt': 1}}}}}}}}}}},\n",
       "       'ত': {'্': {'ব': {' ': {'এ': {'ব': {'ং': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}}}}}}}},\n",
       "  'ম': {'্': {'প': {'া': {'দ': {'ক': {' ': {'স': {'ি': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}},\n",
       "         'গ': {'ো': {'ল': {'া': {'ম': {'TOTAL': 2, '1.11.19.txt': 2}}}}}}}}}}},\n",
       "   'া': {'জ': {'স': {'ে': {'ব': {'ী': {' ': {'ও': {'TOTAL': 2,\n",
       "           '1.11.19.txt': 2},\n",
       "          'শ': {'ম': {'স': {'TOTAL': 2, '1.11.19.txt': 2}}},\n",
       "          'প': {'্': {'র': {'ক': {'ৌ': {'শ': {'ল': {'ী': {'TOTAL': 1,\n",
       "                  '1.11.19.txt': 1}}}}}}}}}}}}}}}}},\n",
       " 'প': {'র': {'ি': {'ক': {'ল': {'্': {'প': {'ন': {'া': {' ': {'হ': {'া': {'ত': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}},\n",
       "           'র': {'য়': {'ে': {'ছ': {'ে': {'।': {'TOTAL': 1,\n",
       "                 '1.11.19.txt': 1}}}}}}}}}}}}},\n",
       "    'চ': {'ি': {'ত': {' ': {'স': {'ভ': {'া': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}},\n",
       "     'া': {'ল': {'ন': {'া': {' ': {'অ': {'ন': {'ু': {'ষ': {'্': {'ঠ': {'া': {'ন': {'TOTAL': 2,\n",
       "                  '1.11.19.txt': 2}}}}}}}}}}},\n",
       "       'ক': {' ': {'স': {'ম': {'া': {'জ': {'স': {'ে': {'ব': {'ী': {'TOTAL': 2,\n",
       "                 '1.11.19.txt': 2}}}}}}}}}}}}},\n",
       "    'ষ': {' ': {'চ': {'ে': {'য়': {'া': {'র': {'ম': {'্': {'য': {'া': {'ন': {'TOTAL': 2,\n",
       "                '1.11.19.txt': 2}}}}}}}}}}}}}},\n",
       "  'ক': {'্': {'ষ': {' ': {'দ': {'ক': {'্': {'ষ': {'ি': {'ণ': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  'া': {'ব': {'ে': {'ন': {'।': {' ': {'শ': {'ু': {'ধ': {'ু': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  '্': {'র': {'য়': {'ো': {'জ': {'ন': {' ': {'আ': {'প': {'ন': {'া': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}},\n",
       "    'ত': {'্': {'য': {'া': {'শ': {'া': {' ': {'ক': {'র': {'ছ': {'ি': {'।': {'TOTAL': 1,\n",
       "                '1.11.19.txt': 1}}}}}}}}}}}},\n",
       "    'ধ': {'া': {'ন': {' ': {'অ': {'ত': {'ি': {'থ': {'ি': {'র': {'TOTAL': 4,\n",
       "              '1.11.19.txt': 4}}}}}},\n",
       "        'ব': {'ক': {'্': {'ত': {'া': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}}}},\n",
       "    'ব': {'া': {'স': {'ী': {' ': {'স': {'ম': {'া': {'জ': {'স': {'ে': {'ব': {'ী': {'TOTAL': 1,\n",
       "                 '1.11.19.txt': 1}}}}}}}}}}}}},\n",
       "    'ক': {'ৌ': {'শ': {'ল': {'ী': {' ': {'উ': {'ম': {'র': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  'ূ': {'র': {'্': {'ণ': {'া': {'ঙ': {'্': {'গ': {' ': {'ক': {'ম': {'ি': {'TOTAL': 2,\n",
       "              '1.11.19.txt': 2}}}}}}}}}}}},\n",
       "  'ঞ': {'্': {'চ': {'া': {'য়': {'ে': {'ত': {' ': {'ক': {'ম': {'ি': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}}},\n",
       " 'হ': {'া': {'ত': {' ': {'হ': {'া': {'ত': {'TOTAL': 13, '1.11.19.txt': 13}}},\n",
       "     'স': {'ি': {'ল': {'ে': {'ট': {'TOTAL': 2, '1.11.19.txt': 2}}}}}}},\n",
       "   'দ': {'ী': {' ': {'ছ': {'য়': {'ফ': {'ু': {'ল': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}}}},\n",
       "  'ক': {' ': {'চ': {'ৌ': {'ধ': {'ু': {'র': {'ী': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}},\n",
       "    'উ': {'প': {'জ': {'ে': {'ল': {'া': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}}},\n",
       "  'ব': {'ে': {'।': {' ': {'আ': {'প': {'ন': {'া': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}}},\n",
       "  'ু': {'ম': {'া': {'য়': {'ু': {'ন': {' ': {'আ': {'হ': {'ম': {'ে': {'দ': {'।': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}}}}}}}},\n",
       " 'আ': {'র': {'ি': {'ফ': {'ু': {'ল': {' ': {'হ': {'ক': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}}},\n",
       "  'প': {'ন': {'া': {' ': {'স': {'দ': {'র': {'TOTAL': 1, '1.11.19.txt': 1}},\n",
       "       'ু': {'প': {'র': {'া': {'ম': {'র': {'্': {'শ': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}},\n",
       "       'হ': {'য': {'ো': {'গ': {'ি': {'ত': {'া': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}}}},\n",
       "      'আ': {'ম': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "  'ম': {' ': {'ক': {'থ': {'TOTAL': 1, '1.11.19.txt': 1}}},\n",
       "   'ি': {' ': {'আ': {'প': {'ন': {'া': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       "  'দ': {'ি': {' ': {'প': {'ূ': {'র': {'্': {'ণ': {'া': {'ঙ': {'্': {'গ': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}}}}}}}},\n",
       "  'জ': {'ম': {' ': {'খ': {'া': {'ন': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "  'হ': {'ম': {'ে': {'দ': {'।': {' ': {'ব': {'ি': {'শ': {'ে': {'ষ': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  'ব': {'্': {'দ': {'ু': {'ল': {' ': {'ব': {'া': {'য়': {'ু': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}},\n",
       "   'ু': {' ': {'জ': {'া': {'হ': {'ি': {'দ': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}}},\n",
       "  'ল': {'ী': {' ': {'ল': {'া': {'উ': {'য়': {'া': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}}}},\n",
       " 'চ': {'ৌ': {'ধ': {'ু': {'র': {'ী': {' ': {'ব': {'ল': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}},\n",
       "        'ম': {'ু': {'ক': {'্': {'ত': {'ি': {'য': {'ো': {'দ': {'্': {'ধ': {'া': {'TOTAL': 1,\n",
       "                    '1.11.19.txt': 1}}}}}}}}}}}}}}}}}},\n",
       "  'ন': {'্': {'ড': {'ি': {'প': {'ু': {'ল': {'স': {'্': {'থ': {' ': {'এ': {'ক': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}}}}}}},\n",
       "  'ে': {'য়': {'া': {'র': {'ম': {'্': {'য': {'া': {'ন': {' ': {'শ': {'ে': {'খ': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}},\n",
       "            'ম': {'ো': {'হ': {'া': {'ম': {'্': {'ম': {'দ': {'TOTAL': 1,\n",
       "                    '1.11.19.txt': 1}}}}}}}}}}}}}}}}},\n",
       "   'ম': {'্': {'ব': {' ': {'প': {'র': {'ি': {'চ': {'া': {'ল': {'ক': {'TOTAL': 2,\n",
       "              '1.11.19.txt': 2}}}}}}}}}}}}},\n",
       " 'ব': {'ল': {' ': {'স': {'ি': {'ল': {'ে': {'ট': {'TOTAL': 1,\n",
       "         '1.11.19.txt': 1}}}}}},\n",
       "   'ে': {'ন': {'।': {' ': {'স': {'ং': {'গ': {'ঠ': {'ন': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  'ু': {'ধ': {'ব': {' ': {'র': {'া': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       "  'ক': {'্': {'ত': {'ব': {'্': {'য': {' ': {'এ': {'স': {'ব': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}},\n",
       "         'দ': {'TOTAL': 15, '1.11.19.txt': 15}}}}},\n",
       "     'া': {' ': {'ছ': {'ি': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       "  'ি': {'শ': {'ে': {'ষ': {' ': {'অ': {'ত': {'ি': {'থ': {'ি': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  'া': {'ব': {'ু': {'ল': {' ': {'স': {'ং': {'গ': {'ঠ': {'ন': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}},\n",
       "   'য়': {'ু': {' ': {'এ': {'ব': {'ং': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}}},\n",
       " 'ত': {'থ': {'া': {' ': {'আ': {'প': {'ন': {'া': {'TOTAL': 1,\n",
       "         '1.11.19.txt': 1}}}}}}},\n",
       "  'ি': {'ন': {'ি': {' ': {'প': {'্': {'র': {'ধ': {'া': {'ন': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}}},\n",
       " 'র': {'য়': {'ে': {'ছ': {'ে': {'।': {' ': {'শ': {'ি': {'গ': {'গ': {'ি': {'র': {'-': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}}}}}}},\n",
       "  'া': {' ': {'স': {'দ': {'র': {'TOTAL': 1, '1.11.19.txt': 1}}}}},\n",
       "  'ফ': {'ি': {'ক': {'ু': {'ল': {' ': {'হ': {'ক': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}}}},\n",
       " 'শ': {'ি': {'গ': {'গ': {'ি': {'র': {'-': {' ': {'দ': {'ৃ': {'শ': {'্': {'য': {'ম': {'া': {'ন': {'TOTAL': 1,\n",
       "                 '1.11.19.txt': 1}}}}}}}}}}}}}},\n",
       "   'ক': {'্': {'ষ': {'া': {'ব': {'ি': {'দ': {' ': {'ড': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  'ু': {'ধ': {'ু': {' ': {'প': {'্': {'র': {'য়': {'ো': {'জ': {'ন': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  'ে': {'খ': {' ': {'ম': {'ো': {'TOTAL': 2, '1.11.19.txt': 2}}}}},\n",
       "  'ম': {'স': {' ': {'জ': {'া': {'ম': {'া': {'ল': {'।': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}}}}},\n",
       " 'এ': {'ব': {'ং': {' ': {'স': {'া': {'র': {'্': {'ব': {'ি': {'ক': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}},\n",
       "      'ম': {'্': {'প': {'া': {'দ': {'ক': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       "     'উ': {'প': {'দ': {'ে': {'ষ': {'্': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}}}},\n",
       "  'ক': {' ': {'ক': {'ম': {'ি': {'উ': {'ন': {'ি': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}}},\n",
       "  'ল': {'া': {'ক': {' ': {'অ': {'র': {'া': {'জ': {'ন': {'ৈ': {'ত': {'ি': {'ক': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}}}}}}},\n",
       "  'স': {'ব': {' ': {'ক': {'থ': {'া': {'TOTAL': 2, '1.11.19.txt': 2}}}}}},\n",
       "  'ছ': {'া': {'ড়': {'া': {' ': {'ব': {'ক': {'্': {'ত': {'ব': {'্': {'য': {'TOTAL': 2,\n",
       "              '1.11.19.txt': 2}}}}}}}}}}}}},\n",
       " 'গ': {'ত': {' ': {'ব': {'ু': {'ধ': {'ব': {'TOTAL': 2, '1.11.19.txt': 2}}}}}},\n",
       "  'ো': {'ল': {'া': {'ম': {' ': {'হ': {'া': {'দ': {'ী': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}}}}},\n",
       " 'ও': {' ': {'প': {'র': {'ি': {'চ': {'ি': {'ত': {'TOTAL': 1,\n",
       "         '1.11.19.txt': 1}}}}}},\n",
       "   'স': {'হ': {'স': {'া': {'ধ': {'া': {'র': {'ণ': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}},\n",
       "    'ং': {'গ': {'ঠ': {'ন': {'TOTAL': 2, '1.11.19.txt': 2}}}},\n",
       "    'ম': {'া': {'জ': {'স': {'ে': {'ব': {'ী': {'TOTAL': 1,\n",
       "           '1.11.19.txt': 1}}}}}}}}}},\n",
       " 'ই': {'উ': {'ন': {'ি': {'য়': {'ন': {' ': {'প': {'র': {'ি': {'ষ': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}},\n",
       "  'স': {'ল': {'া': {'ম': {' ': {'ব': {'া': {'ব': {'ু': {'ল': {'TOTAL': 1,\n",
       "            '1.11.19.txt': 1}}}}}}}}}}},\n",
       " 'খ': {'া': {'ন': {' ': {'ও': {'TOTAL': 1, '1.11.19.txt': 1}}}}},\n",
       " 'ছ': {'য়': {'ফ': {'ু': {'ল': {' ': {'য': {'ৌ': {'থ': {'TOTAL': 1,\n",
       "          '1.11.19.txt': 1}}}}}}}},\n",
       "  'ি': {' ': {'স': {'ি': {'ল': {'ে': {'ট': {'TOTAL': 3,\n",
       "         '1.11.19.txt': 3}}}}}}}},\n",
       " 'য': {'ৌ': {'থ': {' ': {'প': {'র': {'ি': {'চ': {'া': {'ল': {'ন': {'া': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}}},\n",
       "  'ু': {'ক': {'্': {'ত': {'র': {'া': {'ষ': {'্': {'ট': {'্': {'র': {' ': {'প': {'্': {'র': {'ব': {'া': {'স': {'ী': {'TOTAL': 1,\n",
       "                     '1.11.19.txt': 1}}}}}}}}}}}}}}}}}}}},\n",
       " 'উ': {'প': {'দ': {'ে': {'ষ': {'্': {' ': {'হ': {'ু': {'ম': {'া': {'য়': {'ু': {'ন': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}},\n",
       "        'ন': {'জ': {'র': {'ু': {'ল': {'TOTAL': 1, '1.11.19.txt': 1}}}}},\n",
       "        'ড': {'া': {'TOTAL': 1, '1.11.19.txt': 1}},\n",
       "        'ক': {'্': {'র': {'ী': {'ড়': {'া': {'TOTAL': 1,\n",
       "              '1.11.19.txt': 1}}}}}}},\n",
       "       'ট': {'া': {'ম': {'ন': {'্': {'ড': {'ল': {'ী': {'র': {' ': {'স': {'দ': {'স': {'্': {'য': {'TOTAL': 1,\n",
       "                      '1.11.19.txt': 1}}}}}}}}}}}}}}}}}}},\n",
       "   'জ': {'ে': {'ল': {'া': {' ': {'চ': {'ে': {'য়': {'া': {'র': {'ম': {'্': {'য': {'া': {'ন': {'TOTAL': 1,\n",
       "                  '1.11.19.txt': 1}}}}}}}}}}}}}}}},\n",
       "  'ম': {'র': {' ': {'আ': {'ল': {'ী': {'TOTAL': 1, '1.11.19.txt': 1}}}}}}},\n",
       " 'ড': {'া': {' ': {'ম': {'ো': {'TOTAL': 2, '1.11.19.txt': 2}}}},\n",
       "  ' ': {'ক': {'ব': {'ি': {'র': {'TOTAL': 1, '1.11.19.txt': 1}}}}}},\n",
       " 'জ': {'া': {'ম': {'া': {'ল': {'।': {' ': {'এ': {'ছ': {'া': {'ড়': {'া': {'TOTAL': 1,\n",
       "             '1.11.19.txt': 1}}}}}}}}}},\n",
       "   'হ': {'ি': {'দ': {' ': {'য': {'ু': {'ক': {'্': {'ত': {'র': {'া': {'ষ': {'্': {'ট': {'্': {'র': {'TOTAL': 1,\n",
       "                   '1.11.19.txt': 1}}}}}}}}}}}}}}}}}},\n",
       " 'ল': {'া': {'উ': {'য়': {'া': {' ': {'প': {'ঞ': {'্': {'চ': {'া': {'য়': {'ে': {'ত': {'TOTAL': 1,\n",
       "               '1.11.19.txt': 1}}}}}}}}}}}}}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json1_file = open('data.json')\n",
    "TEST_DATA_SET_0 = json1_file.read()\n",
    "DATASET_DICT = json.loads(TEST_DATA_SET_0)\n",
    "DATASET_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITE TO  TRIE(JSON):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for documentID in wordSets:\n",
    "    i = 0\n",
    "    for N_gram in wordSets[documentID]:\n",
    "        i += 1\n",
    "    #    print(str(i)+'/'+str(len(wordSets[documentID]))+' '+N_gram)\n",
    "        CREATE_TRIE(0,N_gram,DATASET_DICT,documentID,wordSets[documentID][N_gram])\n",
    "#DATASET_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(DATASET_DICT, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result = {}\n",
    "Input_wordSets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRIE_CHEACKING(index,N_gram,dictionary,Result_TEMP):\n",
    "    if index < len(N_gram):\n",
    "      #  print('ENtry:'+str(index))\n",
    "      #  print('ENtry:'+N_gram[index])\n",
    "      #  print(dictionary)\n",
    "        if N_gram[index] not in dictionary:\n",
    "        #    print('not in dictionary')\n",
    "            return\n",
    "        else:\n",
    "            TRIE_CHEACKING(index+1,N_gram,dictionary[N_gram[index]],Result_TEMP)\n",
    "    else:\n",
    "        for d in dictionary:\n",
    "            if isinstance(d, dict) is False:\n",
    "       #         print(dictionary[d])\n",
    "                if d not in Result_TEMP:\n",
    "                    Result_TEMP[d] = dictionary[d]\n",
    "                else:\n",
    "                    Result_TEMP[d] += dictionary[d]\n",
    "    return Result_TEMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def INPUT():\n",
    "    Input_wordSets = {}\n",
    "    Input = input()\n",
    "    TestInput = Input.replace('\\ufeff','')\n",
    "    for p in punctuation:\n",
    "         TestInput = TestInput.replace(p, ' ')\n",
    "    #print(TestInput)\n",
    "    TestInput = word_tokenize(TestInput)\n",
    "    TestInput = STOP_WORD_REMOVAL(TestInput)\n",
    "\n",
    "    #steamming\n",
    "    Steamed_Test_Input = []\n",
    "    for TI in TestInput:\n",
    "        temp1 = stemmer.stem_word(TI)\n",
    "        temp = stemmer.stem_word(temp1)\n",
    "        #print(TI+'|'+temp1+'|'+temp)\n",
    "        Steamed_Test_Input.append(temp)\n",
    "\n",
    "    TestInput = N_GRAM_CONVERSION(Synonyms_Removal(Steamed_Test_Input),2) # 2 for 2-gram change in func()\n",
    "    #print(Synonyms_Removal(Steamed_Test_Input))\n",
    "    #TestInput = Synonyms_Removal(stl)\n",
    "\n",
    "    Total_n_grams_words = 0\n",
    "    Uniqe_Word = set(TestInput)\n",
    "    Input_wordSets = dict.fromkeys(Uniqe_Word,0)\n",
    "\n",
    "    for word in TestInput:\n",
    "        Input_wordSets[word] +=1\n",
    "        Total_n_grams_words = Total_n_grams_words + 1\n",
    "    RESULT(Input_wordSets,Total_n_grams_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 3.0\n",
    "def RESULT(Input_wordSets,Total_n_grams_words):\n",
    "    Result = {}\n",
    "    for Iw in Input_wordSets:\n",
    "        #print(Iw)\n",
    "        Result = TRIE_CHEACKING(0,Iw,DATASET_DICT,Result)\n",
    "    print(Result)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT FOUND!!!\n"
     ]
    }
   ],
   "source": [
    "Check_Synonyms_Word('আধার')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "প্রিয় তমঃ আমার অন্ধকার খুব ।  আন্ধার বাস্তবটাকে খুব ভালো দেখতে হয়না।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Total_n_grams_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-b786ee559f4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTotal_n_grams_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Total_n_grams_words' is not defined"
     ]
    }
   ],
   "source": [
    "Total_n_grams_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "সিলেট জেলা আওয়ামী লীগের সহসভাপতি এবং সিলেট-৩ আসনের সাংসদ, বাণিজ্য ও ধর্ম মন্ত্রণালয়ের সংসদীয় স্থায়ী কমিটির সদস্য মাহমুদ উস সামাদ চৌধুরী বলেছেন, \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-861133e7f32d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mINPUT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-1b58b9ee0fc8>\u001b[0m in \u001b[0;36mINPUT\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mInput_wordSets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mTotal_n_grams_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTotal_n_grams_words\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mRESULT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput_wordSets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTotal_n_grams_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-41f9829031d6>\u001b[0m in \u001b[0;36mRESULT\u001b[1;34m(Input_wordSets, Total_n_grams_words)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mIw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mInput_wordSets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#print(Iw)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mResult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATASET_DICT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTRIE_CHEACKING\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResult_TEMP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-68eef8b94653>\u001b[0m in \u001b[0;36mTRIE_CHEACKING\u001b[1;34m(index, N_gram, dictionary, Result_TEMP)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m        \u001b[1;31m#         print(dictionary[d])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mResult_TEMP\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                     \u001b[0mResult_TEMP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "INPUT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TOTAL': 1, '1.11.19.txt': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mariyam flower loves the rose\n",
      "ENtry:0\n",
      "ENtry:t\n",
      "{'D': {'a': {'i': {'s': {'y': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'f': {'l': {'o': {'w': {'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'l': {'o': {'v': {'e': {'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 't': {'h': {'e': {' ': {'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}, 'r': {'o': {'s': {'e': {' ': {'j': {'a': {'s': {'m': {'i': {'n': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}, 'j': {'a': {'s': {'m': {'i': {'n': {'s': {' ': {'i': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'i': {'s': {' ': {'a': {'n': {'o': {'t': {'h': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'a': {'n': {'o': {'t': {'h': {'e': {'r': {' ': {'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}}}, 'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}, 'a': {'n': {'a': {'n': {'a': {' ': {'D': {'a': {'i': {'s': {'y': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'm': {'o': {'n': {'k': {'e': {'y': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}}\n",
      "ENtry:1\n",
      "ENtry:h\n",
      "{'h': {'e': {' ': {'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}\n",
      "ENtry:2\n",
      "ENtry:e\n",
      "{'e': {' ': {'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}\n",
      "ENtry:3\n",
      "ENtry: \n",
      "{' ': {'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}\n",
      "ENtry:4\n",
      "ENtry:r\n",
      "{'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}\n",
      "ENtry:5\n",
      "ENtry:o\n",
      "{'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}\n",
      "ENtry:6\n",
      "ENtry:s\n",
      "{'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}\n",
      "ENtry:7\n",
      "ENtry:e\n",
      "{'e': {'TOTAL': 1, 'Flower.txt': 1}}\n",
      "1\n",
      "1\n",
      "ENtry:0\n",
      "ENtry:f\n",
      "{'D': {'a': {'i': {'s': {'y': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'f': {'l': {'o': {'w': {'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'l': {'o': {'v': {'e': {'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 't': {'h': {'e': {' ': {'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}, 'r': {'o': {'s': {'e': {' ': {'j': {'a': {'s': {'m': {'i': {'n': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}, 'j': {'a': {'s': {'m': {'i': {'n': {'s': {' ': {'i': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'i': {'s': {' ': {'a': {'n': {'o': {'t': {'h': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'a': {'n': {'o': {'t': {'h': {'e': {'r': {' ': {'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}}}, 'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}, 'a': {'n': {'a': {'n': {'a': {' ': {'D': {'a': {'i': {'s': {'y': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'm': {'o': {'n': {'k': {'e': {'y': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}}\n",
      "ENtry:1\n",
      "ENtry:l\n",
      "{'l': {'o': {'w': {'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}\n",
      "ENtry:2\n",
      "ENtry:o\n",
      "{'o': {'w': {'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}\n",
      "ENtry:3\n",
      "ENtry:w\n",
      "{'w': {'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}\n",
      "ENtry:4\n",
      "ENtry:e\n",
      "{'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}\n",
      "ENtry:5\n",
      "ENtry:r\n",
      "{'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}\n",
      "ENtry:6\n",
      "ENtry: \n",
      "{' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}\n",
      "ENtry:7\n",
      "ENtry:l\n",
      "{'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}\n",
      "ENtry:8\n",
      "ENtry:o\n",
      "{'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}\n",
      "ENtry:9\n",
      "ENtry:v\n",
      "{'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}\n",
      "ENtry:10\n",
      "ENtry:e\n",
      "{'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}\n",
      "ENtry:11\n",
      "ENtry:s\n",
      "{'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}\n",
      "2\n",
      "1\n",
      "1\n",
      "ENtry:0\n",
      "ENtry:l\n",
      "{'D': {'a': {'i': {'s': {'y': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'f': {'l': {'o': {'w': {'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'l': {'o': {'v': {'e': {'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 't': {'h': {'e': {' ': {'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}, 'r': {'o': {'s': {'e': {' ': {'j': {'a': {'s': {'m': {'i': {'n': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}, 'j': {'a': {'s': {'m': {'i': {'n': {'s': {' ': {'i': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'i': {'s': {' ': {'a': {'n': {'o': {'t': {'h': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'a': {'n': {'o': {'t': {'h': {'e': {'r': {' ': {'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}}}, 'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}, 'a': {'n': {'a': {'n': {'a': {' ': {'D': {'a': {'i': {'s': {'y': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'm': {'o': {'n': {'k': {'e': {'y': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}}\n",
      "ENtry:1\n",
      "ENtry:o\n",
      "{'o': {'v': {'e': {'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}\n",
      "ENtry:2\n",
      "ENtry:v\n",
      "{'v': {'e': {'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}\n",
      "ENtry:3\n",
      "ENtry:e\n",
      "{'e': {'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}\n",
      "ENtry:4\n",
      "ENtry:s\n",
      "{'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}\n",
      "ENtry:5\n",
      "ENtry: \n",
      "{' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}\n",
      "ENtry:6\n",
      "ENtry:t\n",
      "{'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}\n",
      "ENtry:7\n",
      "ENtry:h\n",
      "{'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}\n",
      "ENtry:8\n",
      "ENtry:e\n",
      "{'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}\n",
      "2\n",
      "1\n",
      "1\n",
      "ENtry:0\n",
      "ENtry:M\n",
      "{'D': {'a': {'i': {'s': {'y': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'f': {'l': {'o': {'w': {'e': {'r': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'l': {'o': {'v': {'e': {'s': {' ': {'t': {'h': {'e': {'TOTAL': 2, 'Flower.txt': 1, 'Fruits.txt': 1}}}, 'b': {'a': {'n': {'a': {'n': {'a': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 't': {'h': {'e': {' ': {'r': {'o': {'s': {'e': {'TOTAL': 1, 'Flower.txt': 1}}}}, 'a': {'p': {'p': {'l': {'e': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}, 'r': {'o': {'s': {'e': {' ': {'j': {'a': {'s': {'m': {'i': {'n': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}, 'j': {'a': {'s': {'m': {'i': {'n': {'s': {' ': {'i': {'s': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'i': {'s': {' ': {'a': {'n': {'o': {'t': {'h': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}, 'a': {'n': {'o': {'t': {'h': {'e': {'r': {' ': {'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}}}, 'b': {'e': {'a': {'u': {'t': {'i': {'f': {'u': {'l': {' ': {'f': {'l': {'o': {'w': {'e': {'r': {'TOTAL': 1, 'Flower.txt': 1}}}}}}}}}}}}}}}, 'a': {'n': {'a': {'n': {'a': {' ': {'D': {'a': {'i': {'s': {'y': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}, 'm': {'o': {'n': {'k': {'e': {'y': {' ': {'l': {'o': {'v': {'e': {'s': {'TOTAL': 1, 'Fruits.txt': 1}}}}}}}}}}}}}\n",
      "not in dictionary\n"
     ]
    }
   ],
   "source": [
    "INPUT()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
